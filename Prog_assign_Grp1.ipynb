{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prog_assign.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Predicting fake news using word embeddings and comparing their performance**"
      ],
      "metadata": {
        "id": "3dl0JyuYpG1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We have fake and real news dataset. Link to the dataset: \"https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset?select=Fake.csv\".\n",
        "#The dataset contains the following columns: \"title\",\"text\",\"subject\",\"date\". There are two seperate dataset for fake and real news.\n",
        "#We take 500 rows from both dataset and then combine them to form a single dataset with additional column conveying whether news is real or fake.\n",
        "#Then we use word embedding models to create vector from the available news text column.\n",
        "#The word embeddings used are: word2vec, BERT-base, BERT-Large and AlBERT.\n",
        "#After creating the vectors from these word embedding models, we train a binary classification model to predict whether news is real or fake.\n",
        "#Our novel application with this programming assignment is that we are comparing various word embedding models on this specific task of fake news prediction.\n",
        "#Word embeddings play a huge role in predicting the label. The vector produced includes various features in numerical form which differs from model to model.\n",
        "#We try to figure out which word embedding model creates the best vectors assisting in predicting fake news.\n",
        "#The explanation is given at each step in respective code chunks.\n",
        "#The results are summarised at the end."
      ],
      "metadata": {
        "id": "DdlpipivpGNI"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tYW2XYiM_qoI"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.0-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"spark-3.2.0-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "tRKjg8jQ_ucj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "YRc73NPs_uYd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "sc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "ABgZ39C4_uUP",
        "outputId": "25558fad-3de2-416b-8ba3-516f6f74c52f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=pyspark-shell>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://e5fdaa645c63:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Connecting to google drive**"
      ],
      "metadata": {
        "id": "T3sClkd0uZKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF1W4qlt_uOe",
        "outputId": "a27c1377-e709-467f-9b05-2aac9151ccf4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading the datasets**"
      ],
      "metadata": {
        "id": "rVUdhyMvud5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fakepath = '/content/drive/MyDrive/NLP/Fake.csv'"
      ],
      "metadata": {
        "id": "6iOvzXYH_uCR"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "truepath = '/content/drive/MyDrive/NLP/True.csv'"
      ],
      "metadata": {
        "id": "HE2hn6Gg_t7o"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fakenews = spark.read.csv(fakepath, header = True)"
      ],
      "metadata": {
        "id": "itj0TqF6_tzz"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fakenews.show(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fI9J5WsA9aV",
        "outputId": "509dd597-244e-4c25-de42-d4b624434d03"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-------+-----------------+\n",
            "|               title|                text|subject|             date|\n",
            "+--------------------+--------------------+-------+-----------------+\n",
            "| Donald Trump Sen...|Donald Trump just...|   News|December 31, 2017|\n",
            "| Drunk Bragging T...|House Intelligenc...|   News|December 31, 2017|\n",
            "| Sheriff David Cl...|On Friday, it was...|   News|December 30, 2017|\n",
            "| Trump Is So Obse...|On Christmas day,...|   News|December 29, 2017|\n",
            "| Pope Francis Jus...|Pope Francis used...|   News|December 25, 2017|\n",
            "| Racist Alabama C...|The number of cas...|   News|December 25, 2017|\n",
            "| Fresh Off The Go...|Donald Trump spen...|   News|December 23, 2017|\n",
            "| Trump Said Some ...|In the wake of ye...|   News|December 23, 2017|\n",
            "| Former CIA Direc...|Many people have ...|   News|December 22, 2017|\n",
            "| WATCH: Brand-New...|Just when you mig...|   News|December 21, 2017|\n",
            "| Papa Johnâ€™s Foun...|A centerpiece of ...|   News|December 21, 2017|\n",
            "| WATCH: Paul Ryan...|Republicans are w...|   News|December 21, 2017|\n",
            "| Bad News For Tru...|Republicans have ...|   News|December 21, 2017|\n",
            "| WATCH: Lindsey G...|The media has bee...|   News|December 20, 2017|\n",
            "| Heiress To Disne...|Abigail Disney is...|   News|December 20, 2017|\n",
            "| Tone Deaf Trump:...|Donald Trump just...|   News|December 20, 2017|\n",
            "| The Internet Bru...|A new animatronic...|   News|December 19, 2017|\n",
            "| Mueller Spokesma...|Trump supporters ...|   News|December 17, 2017|\n",
            "| SNL Hilariously ...|Right now, the wh...|   News|December 17, 2017|\n",
            "| Republican Senat...|Senate Majority W...|   News|December 16, 2017|\n",
            "+--------------------+--------------------+-------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "truenews = spark.read.csv(truepath, header = True)"
      ],
      "metadata": {
        "id": "STF860MTBFXM"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "truenews.show(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaiGwpXuBFU5",
        "outputId": "30ba5940-c9b1-4b95-be31-9cb010ba34d0"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+------------------+\n",
            "|               title|                text|             subject|              date|\n",
            "+--------------------+--------------------+--------------------+------------------+\n",
            "|As U.S. budget fi...|WASHINGTON (Reute...|        politicsNews|December 31, 2017 |\n",
            "|U.S. military to ...|WASHINGTON (Reute...|        politicsNews|December 29, 2017 |\n",
            "|Senior U.S. Repub...|WASHINGTON (Reute...|        politicsNews|December 31, 2017 |\n",
            "|FBI Russia probe ...|WASHINGTON (Reute...|        politicsNews|December 30, 2017 |\n",
            "|Trump wants Posta...|SEATTLE/WASHINGTO...|        politicsNews|December 29, 2017 |\n",
            "|White House, Cong...|WEST PALM BEACH, ...|        politicsNews|December 29, 2017 |\n",
            "|Trump says Russia...|WEST PALM BEACH, ...|        politicsNews|December 29, 2017 |\n",
            "|Factbox: Trump on...|The following sta...|        politicsNews|December 29, 2017 |\n",
            "|Trump on Twitter ...|The following sta...|        politicsNews|December 29, 2017 |\n",
            "|Alabama official ...|WASHINGTON (Reute...|        politicsNews|December 28, 2017 |\n",
            "|Jones certified U...|(Reuters) - Alaba...|        politicsNews|December 28, 2017 |\n",
            "|New York governor...|NEW YORK/WASHINGT...|        politicsNews|December 28, 2017 |\n",
            "|Factbox: Trump on...|The following sta...|        politicsNews|December 28, 2017 |\n",
            "|Trump on Twitter ...|\"The following st...| Associates Up 83...|      politicsNews|\n",
            "|Man says he deliv...| (In Dec. 25 stor...|        politicsNews|December 25, 2017 |\n",
            "|Virginia official...|(Reuters) - A lot...|        politicsNews|December 27, 2017 |\n",
            "|U.S. lawmakers qu...|WASHINGTON (Reute...|        politicsNews|December 27, 2017 |\n",
            "|Trump on Twitter ...|The following sta...|        politicsNews|December 26, 2017 |\n",
            "|U.S. appeals cour...|(Reuters) - A U.S...|        politicsNews|December 26, 2017 |\n",
            "|Treasury Secretar...|(Reuters) - A gif...|        politicsNews|December 24, 2017 |\n",
            "+--------------------+--------------------+--------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting both dataframes to pandas dataframe and sampling random 500 rows from both the dataframes\n",
        "import pandas as pd\n",
        "fakenewspd = fakenews.toPandas()\n",
        "fakenewspd = fakenewspd.sample(n=500, random_state=2)\n",
        "fakenewspd.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3Ct7AcZ7BFPw",
        "outputId": "f21d4cb2-3a4b-46dc-d16e-2b41cd289a86"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   title  \\\n",
              "15154  CASTRO IGNORES DISASTROUS COMMUNIST POLICIES T...   \n",
              "7624    Gun Industry Has NO SHAME In Their PATHETIC S...   \n",
              "12996  STUNNING DEVELOPMENT: OBAMA GIVES $75 MILLION ...   \n",
              "14424  STUNNING! FORMER DISNEY TECH WORKERâ€™S Emotiona...   \n",
              "20655  LONG TIME DEMOCRATS, UNION WORKERS Explain Why...   \n",
              "\n",
              "                                                    text    subject  \\\n",
              "15154  If Obama had a communist friend he d be this p...   politics   \n",
              "7624   While one could argue that the Second Amendmen...       News   \n",
              "12996  You have got to be kidding me! After all the t...   politics   \n",
              "14424                                                      politics   \n",
              "20655  As millions of dollars of union dues flow into...  left-news   \n",
              "\n",
              "                date  \n",
              "15154   Sep 29, 2015  \n",
              "7624   March 8, 2016  \n",
              "12996   Sep 17, 2016  \n",
              "14424   Feb 25, 2016  \n",
              "20655    May 1, 2016  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7be178b-0edd-4ff8-849d-8c0e8c79d633\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15154</th>\n",
              "      <td>CASTRO IGNORES DISASTROUS COMMUNIST POLICIES T...</td>\n",
              "      <td>If Obama had a communist friend he d be this p...</td>\n",
              "      <td>politics</td>\n",
              "      <td>Sep 29, 2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7624</th>\n",
              "      <td>Gun Industry Has NO SHAME In Their PATHETIC S...</td>\n",
              "      <td>While one could argue that the Second Amendmen...</td>\n",
              "      <td>News</td>\n",
              "      <td>March 8, 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12996</th>\n",
              "      <td>STUNNING DEVELOPMENT: OBAMA GIVES $75 MILLION ...</td>\n",
              "      <td>You have got to be kidding me! After all the t...</td>\n",
              "      <td>politics</td>\n",
              "      <td>Sep 17, 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14424</th>\n",
              "      <td>STUNNING! FORMER DISNEY TECH WORKERâ€™S Emotiona...</td>\n",
              "      <td></td>\n",
              "      <td>politics</td>\n",
              "      <td>Feb 25, 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20655</th>\n",
              "      <td>LONG TIME DEMOCRATS, UNION WORKERS Explain Why...</td>\n",
              "      <td>As millions of dollars of union dues flow into...</td>\n",
              "      <td>left-news</td>\n",
              "      <td>May 1, 2016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7be178b-0edd-4ff8-849d-8c0e8c79d633')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7be178b-0edd-4ff8-849d-8c0e8c79d633 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7be178b-0edd-4ff8-849d-8c0e8c79d633');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "truenewspd = truenews.toPandas()\n",
        "truenewspd = truenewspd.sample(n=500,random_state=2)\n",
        "truenewspd.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wHGi1ZlYBFLr",
        "outputId": "8631ba8a-0ccb-4236-ab9f-23e8a1c35e38"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   title  \\\n",
              "6176   'Numerous' arrests made during Trump inaugurat...   \n",
              "8278   Trump calls for new civil rights agenda in vis...   \n",
              "14529  U.S. urges African nations to press North Kore...   \n",
              "10614  Congresswoman quits Democratic National Commit...   \n",
              "2705   Trump, after Senate bill collapses, vows 'grea...   \n",
              "\n",
              "                                                    text       subject  \\\n",
              "6176   WASHINGTON (Reuters) - Washington police made ...  politicsNews   \n",
              "8278   DETROIT (Reuters) - Republican presidential ca...  politicsNews   \n",
              "14529  WASHINGTON (Reuters) - U.S. Secretary of State...     worldnews   \n",
              "10614  WASHINGTON (Reuters) - Democratic National Com...  politicsNews   \n",
              "2705   WASHINGTON (Reuters) - After Republicansâ€™ effo...  politicsNews   \n",
              "\n",
              "                     date  \n",
              "6176    January 20, 2017   \n",
              "8278   September 3, 2016   \n",
              "14529  November 17, 2017   \n",
              "10614  February 28, 2016   \n",
              "2705       July 18, 2017   "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2f459d84-a3ba-4dc8-9700-5a8523642336\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6176</th>\n",
              "      <td>'Numerous' arrests made during Trump inaugurat...</td>\n",
              "      <td>WASHINGTON (Reuters) - Washington police made ...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>January 20, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8278</th>\n",
              "      <td>Trump calls for new civil rights agenda in vis...</td>\n",
              "      <td>DETROIT (Reuters) - Republican presidential ca...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>September 3, 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14529</th>\n",
              "      <td>U.S. urges African nations to press North Kore...</td>\n",
              "      <td>WASHINGTON (Reuters) - U.S. Secretary of State...</td>\n",
              "      <td>worldnews</td>\n",
              "      <td>November 17, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10614</th>\n",
              "      <td>Congresswoman quits Democratic National Commit...</td>\n",
              "      <td>WASHINGTON (Reuters) - Democratic National Com...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>February 28, 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2705</th>\n",
              "      <td>Trump, after Senate bill collapses, vows 'grea...</td>\n",
              "      <td>WASHINGTON (Reuters) - After Republicansâ€™ effo...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>July 18, 2017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f459d84-a3ba-4dc8-9700-5a8523642336')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2f459d84-a3ba-4dc8-9700-5a8523642336 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2f459d84-a3ba-4dc8-9700-5a8523642336');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding newstype column to both the dataframes\n",
        "fakenewspd[\"newstype\"] = [\"fake\"]*len(fakenewspd)"
      ],
      "metadata": {
        "id": "AfWcBNO9C8-F"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fakenewspd.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hvZxpoH0DDlb",
        "outputId": "170b5f6a-7fda-4a68-fb59-f5945c509d78"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   title  \\\n",
              "15154  CASTRO IGNORES DISASTROUS COMMUNIST POLICIES T...   \n",
              "7624    Gun Industry Has NO SHAME In Their PATHETIC S...   \n",
              "12996  STUNNING DEVELOPMENT: OBAMA GIVES $75 MILLION ...   \n",
              "14424  STUNNING! FORMER DISNEY TECH WORKERâ€™S Emotiona...   \n",
              "20655  LONG TIME DEMOCRATS, UNION WORKERS Explain Why...   \n",
              "\n",
              "                                                    text    subject  \\\n",
              "15154  If Obama had a communist friend he d be this p...   politics   \n",
              "7624   While one could argue that the Second Amendmen...       News   \n",
              "12996  You have got to be kidding me! After all the t...   politics   \n",
              "14424                                                      politics   \n",
              "20655  As millions of dollars of union dues flow into...  left-news   \n",
              "\n",
              "                date newstype  \n",
              "15154   Sep 29, 2015     fake  \n",
              "7624   March 8, 2016     fake  \n",
              "12996   Sep 17, 2016     fake  \n",
              "14424   Feb 25, 2016     fake  \n",
              "20655    May 1, 2016     fake  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-76e00c1e-0e65-47c3-b320-5f5bc8bbdf29\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>newstype</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15154</th>\n",
              "      <td>CASTRO IGNORES DISASTROUS COMMUNIST POLICIES T...</td>\n",
              "      <td>If Obama had a communist friend he d be this p...</td>\n",
              "      <td>politics</td>\n",
              "      <td>Sep 29, 2015</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7624</th>\n",
              "      <td>Gun Industry Has NO SHAME In Their PATHETIC S...</td>\n",
              "      <td>While one could argue that the Second Amendmen...</td>\n",
              "      <td>News</td>\n",
              "      <td>March 8, 2016</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12996</th>\n",
              "      <td>STUNNING DEVELOPMENT: OBAMA GIVES $75 MILLION ...</td>\n",
              "      <td>You have got to be kidding me! After all the t...</td>\n",
              "      <td>politics</td>\n",
              "      <td>Sep 17, 2016</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14424</th>\n",
              "      <td>STUNNING! FORMER DISNEY TECH WORKERâ€™S Emotiona...</td>\n",
              "      <td></td>\n",
              "      <td>politics</td>\n",
              "      <td>Feb 25, 2016</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20655</th>\n",
              "      <td>LONG TIME DEMOCRATS, UNION WORKERS Explain Why...</td>\n",
              "      <td>As millions of dollars of union dues flow into...</td>\n",
              "      <td>left-news</td>\n",
              "      <td>May 1, 2016</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76e00c1e-0e65-47c3-b320-5f5bc8bbdf29')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-76e00c1e-0e65-47c3-b320-5f5bc8bbdf29 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-76e00c1e-0e65-47c3-b320-5f5bc8bbdf29');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "truenewspd[\"newstype\"] = [\"true\"]*len(truenewspd)"
      ],
      "metadata": {
        "id": "0HLyco6iBFAr"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "truenewspd.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YdTp6tbnBE4S",
        "outputId": "8d399f26-5525-42f2-d879-3039fc89fa0a"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   title  \\\n",
              "6176   'Numerous' arrests made during Trump inaugurat...   \n",
              "8278   Trump calls for new civil rights agenda in vis...   \n",
              "14529  U.S. urges African nations to press North Kore...   \n",
              "10614  Congresswoman quits Democratic National Commit...   \n",
              "2705   Trump, after Senate bill collapses, vows 'grea...   \n",
              "\n",
              "                                                    text       subject  \\\n",
              "6176   WASHINGTON (Reuters) - Washington police made ...  politicsNews   \n",
              "8278   DETROIT (Reuters) - Republican presidential ca...  politicsNews   \n",
              "14529  WASHINGTON (Reuters) - U.S. Secretary of State...     worldnews   \n",
              "10614  WASHINGTON (Reuters) - Democratic National Com...  politicsNews   \n",
              "2705   WASHINGTON (Reuters) - After Republicansâ€™ effo...  politicsNews   \n",
              "\n",
              "                     date newstype  \n",
              "6176    January 20, 2017      true  \n",
              "8278   September 3, 2016      true  \n",
              "14529  November 17, 2017      true  \n",
              "10614  February 28, 2016      true  \n",
              "2705       July 18, 2017      true  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b299738-1cb6-4152-b0a8-8eb43ef29909\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>newstype</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6176</th>\n",
              "      <td>'Numerous' arrests made during Trump inaugurat...</td>\n",
              "      <td>WASHINGTON (Reuters) - Washington police made ...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>January 20, 2017</td>\n",
              "      <td>true</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8278</th>\n",
              "      <td>Trump calls for new civil rights agenda in vis...</td>\n",
              "      <td>DETROIT (Reuters) - Republican presidential ca...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>September 3, 2016</td>\n",
              "      <td>true</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14529</th>\n",
              "      <td>U.S. urges African nations to press North Kore...</td>\n",
              "      <td>WASHINGTON (Reuters) - U.S. Secretary of State...</td>\n",
              "      <td>worldnews</td>\n",
              "      <td>November 17, 2017</td>\n",
              "      <td>true</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10614</th>\n",
              "      <td>Congresswoman quits Democratic National Commit...</td>\n",
              "      <td>WASHINGTON (Reuters) - Democratic National Com...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>February 28, 2016</td>\n",
              "      <td>true</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2705</th>\n",
              "      <td>Trump, after Senate bill collapses, vows 'grea...</td>\n",
              "      <td>WASHINGTON (Reuters) - After Republicansâ€™ effo...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>July 18, 2017</td>\n",
              "      <td>true</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b299738-1cb6-4152-b0a8-8eb43ef29909')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b299738-1cb6-4152-b0a8-8eb43ef29909 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b299738-1cb6-4152-b0a8-8eb43ef29909');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Joining both the dataframes as a single dataframe\n",
        "news = pd.concat([fakenewspd,truenewspd])"
      ],
      "metadata": {
        "id": "zCh3qKhSBE1l"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "az_4u0TbBEyi",
        "outputId": "4bb17a38-82df-4e7d-874c-d7bba02a055e"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   title  \\\n",
              "15154  CASTRO IGNORES DISASTROUS COMMUNIST POLICIES T...   \n",
              "7624    Gun Industry Has NO SHAME In Their PATHETIC S...   \n",
              "12996  STUNNING DEVELOPMENT: OBAMA GIVES $75 MILLION ...   \n",
              "14424  STUNNING! FORMER DISNEY TECH WORKERâ€™S Emotiona...   \n",
              "20655  LONG TIME DEMOCRATS, UNION WORKERS Explain Why...   \n",
              "\n",
              "                                                    text    subject  \\\n",
              "15154  If Obama had a communist friend he d be this p...   politics   \n",
              "7624   While one could argue that the Second Amendmen...       News   \n",
              "12996  You have got to be kidding me! After all the t...   politics   \n",
              "14424                                                      politics   \n",
              "20655  As millions of dollars of union dues flow into...  left-news   \n",
              "\n",
              "                date newstype  \n",
              "15154   Sep 29, 2015     fake  \n",
              "7624   March 8, 2016     fake  \n",
              "12996   Sep 17, 2016     fake  \n",
              "14424   Feb 25, 2016     fake  \n",
              "20655    May 1, 2016     fake  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ac48d45-b2e7-42bc-8208-9a9ef9446e89\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>newstype</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15154</th>\n",
              "      <td>CASTRO IGNORES DISASTROUS COMMUNIST POLICIES T...</td>\n",
              "      <td>If Obama had a communist friend he d be this p...</td>\n",
              "      <td>politics</td>\n",
              "      <td>Sep 29, 2015</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7624</th>\n",
              "      <td>Gun Industry Has NO SHAME In Their PATHETIC S...</td>\n",
              "      <td>While one could argue that the Second Amendmen...</td>\n",
              "      <td>News</td>\n",
              "      <td>March 8, 2016</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12996</th>\n",
              "      <td>STUNNING DEVELOPMENT: OBAMA GIVES $75 MILLION ...</td>\n",
              "      <td>You have got to be kidding me! After all the t...</td>\n",
              "      <td>politics</td>\n",
              "      <td>Sep 17, 2016</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14424</th>\n",
              "      <td>STUNNING! FORMER DISNEY TECH WORKERâ€™S Emotiona...</td>\n",
              "      <td></td>\n",
              "      <td>politics</td>\n",
              "      <td>Feb 25, 2016</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20655</th>\n",
              "      <td>LONG TIME DEMOCRATS, UNION WORKERS Explain Why...</td>\n",
              "      <td>As millions of dollars of union dues flow into...</td>\n",
              "      <td>left-news</td>\n",
              "      <td>May 1, 2016</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ac48d45-b2e7-42bc-8208-9a9ef9446e89')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1ac48d45-b2e7-42bc-8208-9a9ef9446e89 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1ac48d45-b2e7-42bc-8208-9a9ef9446e89');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news['newstype'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dh8sDC5SGiGu",
        "outputId": "04a74856-d526-4984-fa0b-369a0b2de258"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fake    500\n",
              "true    500\n",
              "Name: newstype, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding a column - \"Fake\", which has boolean values. 1 if news is fake and 0 if news is true\n",
        "news['fake'] = news['newstype'].apply(lambda x : 1 if x == \"fake\" else 0)"
      ],
      "metadata": {
        "id": "IDQttmr9HsA7"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-s5EPnh5IVyZ",
        "outputId": "f1c00769-e8a8-4882-f7b3-5507cc4d47b9"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   title  \\\n",
              "15154  CASTRO IGNORES DISASTROUS COMMUNIST POLICIES T...   \n",
              "7624    Gun Industry Has NO SHAME In Their PATHETIC S...   \n",
              "12996  STUNNING DEVELOPMENT: OBAMA GIVES $75 MILLION ...   \n",
              "14424  STUNNING! FORMER DISNEY TECH WORKERâ€™S Emotiona...   \n",
              "20655  LONG TIME DEMOCRATS, UNION WORKERS Explain Why...   \n",
              "\n",
              "                                                    text    subject  \\\n",
              "15154  If Obama had a communist friend he d be this p...   politics   \n",
              "7624   While one could argue that the Second Amendmen...       News   \n",
              "12996  You have got to be kidding me! After all the t...   politics   \n",
              "14424                                                      politics   \n",
              "20655  As millions of dollars of union dues flow into...  left-news   \n",
              "\n",
              "                date newstype  fake  \n",
              "15154   Sep 29, 2015     fake     1  \n",
              "7624   March 8, 2016     fake     1  \n",
              "12996   Sep 17, 2016     fake     1  \n",
              "14424   Feb 25, 2016     fake     1  \n",
              "20655    May 1, 2016     fake     1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf819d8e-9394-4b5a-8e88-737b061d248c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>newstype</th>\n",
              "      <th>fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15154</th>\n",
              "      <td>CASTRO IGNORES DISASTROUS COMMUNIST POLICIES T...</td>\n",
              "      <td>If Obama had a communist friend he d be this p...</td>\n",
              "      <td>politics</td>\n",
              "      <td>Sep 29, 2015</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7624</th>\n",
              "      <td>Gun Industry Has NO SHAME In Their PATHETIC S...</td>\n",
              "      <td>While one could argue that the Second Amendmen...</td>\n",
              "      <td>News</td>\n",
              "      <td>March 8, 2016</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12996</th>\n",
              "      <td>STUNNING DEVELOPMENT: OBAMA GIVES $75 MILLION ...</td>\n",
              "      <td>You have got to be kidding me! After all the t...</td>\n",
              "      <td>politics</td>\n",
              "      <td>Sep 17, 2016</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14424</th>\n",
              "      <td>STUNNING! FORMER DISNEY TECH WORKERâ€™S Emotiona...</td>\n",
              "      <td></td>\n",
              "      <td>politics</td>\n",
              "      <td>Feb 25, 2016</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20655</th>\n",
              "      <td>LONG TIME DEMOCRATS, UNION WORKERS Explain Why...</td>\n",
              "      <td>As millions of dollars of union dues flow into...</td>\n",
              "      <td>left-news</td>\n",
              "      <td>May 1, 2016</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf819d8e-9394-4b5a-8e88-737b061d248c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bf819d8e-9394-4b5a-8e88-737b061d248c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bf819d8e-9394-4b5a-8e88-737b061d248c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news['fake'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA7V2qxpIY7O",
        "outputId": "685b7c72-10fb-4b3a-b61e-f909f86e6feb"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    500\n",
              "0    500\n",
              "Name: fake, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing all rows with null values\n",
        "news1 = news.dropna()"
      ],
      "metadata": {
        "id": "mvnbZBw0LMvX"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news1['fake'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc3JT5KmLRaY",
        "outputId": "b7920dcd-6898-4cfa-aae1-225e769cae9e"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    500\n",
              "0    500\n",
              "Name: fake, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Word2Vec text embedding**"
      ],
      "metadata": {
        "id": "7R_8qYzoxmhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Word2vec text embedding will generate vectors for each word in the sentence\n",
        "#It will not generate a single vector for a sentence\n",
        "#Here we clean the text part and generate vectors for each word in the text\n",
        "#After this step, we split our dataset into test and train\n",
        "#Then we combine the vectors of all words in a sentence in an array\n",
        "#Next, we take average of all elements of vectors in a sentence to form a single vector for each sentence\n",
        "#After getting the vectors, we train the random forest classification model and use these vectors as input\n",
        "#Then at last, we evaluate our model by making predictions on test set and measuring accuracy, recall and precision"
      ],
      "metadata": {
        "id": "K7qOJUoCxwa4"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "1Z3oLP8nWuVh"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Clean data using the built in cleaner in gensim\n",
        "news1['text_clean'] = news1['text'].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
        "news1.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "KF3J9-dcWuTk",
        "outputId": "39e175f1-c35e-4832-8f56-2b9a8872909f"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   title  \\\n",
              "15154  CASTRO IGNORES DISASTROUS COMMUNIST POLICIES T...   \n",
              "7624    Gun Industry Has NO SHAME In Their PATHETIC S...   \n",
              "12996  STUNNING DEVELOPMENT: OBAMA GIVES $75 MILLION ...   \n",
              "14424  STUNNING! FORMER DISNEY TECH WORKERâ€™S Emotiona...   \n",
              "20655  LONG TIME DEMOCRATS, UNION WORKERS Explain Why...   \n",
              "\n",
              "                                                    text    subject  \\\n",
              "15154  If Obama had a communist friend he d be this p...   politics   \n",
              "7624   While one could argue that the Second Amendmen...       News   \n",
              "12996  You have got to be kidding me! After all the t...   politics   \n",
              "14424                                                      politics   \n",
              "20655  As millions of dollars of union dues flow into...  left-news   \n",
              "\n",
              "                date newstype  fake  \\\n",
              "15154   Sep 29, 2015     fake     1   \n",
              "7624   March 8, 2016     fake     1   \n",
              "12996   Sep 17, 2016     fake     1   \n",
              "14424   Feb 25, 2016     fake     1   \n",
              "20655    May 1, 2016     fake     1   \n",
              "\n",
              "                                              text_clean  \n",
              "15154  [if, obama, had, communist, friend, he, be, th...  \n",
              "7624   [while, one, could, argue, that, the, second, ...  \n",
              "12996  [you, have, got, to, be, kidding, me, after, a...  \n",
              "14424                                                 []  \n",
              "20655  [as, millions, of, dollars, of, union, dues, f...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43992cdf-03c0-4edd-8e23-6295ba441b03\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>newstype</th>\n",
              "      <th>fake</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15154</th>\n",
              "      <td>CASTRO IGNORES DISASTROUS COMMUNIST POLICIES T...</td>\n",
              "      <td>If Obama had a communist friend he d be this p...</td>\n",
              "      <td>politics</td>\n",
              "      <td>Sep 29, 2015</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>[if, obama, had, communist, friend, he, be, th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7624</th>\n",
              "      <td>Gun Industry Has NO SHAME In Their PATHETIC S...</td>\n",
              "      <td>While one could argue that the Second Amendmen...</td>\n",
              "      <td>News</td>\n",
              "      <td>March 8, 2016</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>[while, one, could, argue, that, the, second, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12996</th>\n",
              "      <td>STUNNING DEVELOPMENT: OBAMA GIVES $75 MILLION ...</td>\n",
              "      <td>You have got to be kidding me! After all the t...</td>\n",
              "      <td>politics</td>\n",
              "      <td>Sep 17, 2016</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>[you, have, got, to, be, kidding, me, after, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14424</th>\n",
              "      <td>STUNNING! FORMER DISNEY TECH WORKERâ€™S Emotiona...</td>\n",
              "      <td></td>\n",
              "      <td>politics</td>\n",
              "      <td>Feb 25, 2016</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20655</th>\n",
              "      <td>LONG TIME DEMOCRATS, UNION WORKERS Explain Why...</td>\n",
              "      <td>As millions of dollars of union dues flow into...</td>\n",
              "      <td>left-news</td>\n",
              "      <td>May 1, 2016</td>\n",
              "      <td>fake</td>\n",
              "      <td>1</td>\n",
              "      <td>[as, millions, of, dollars, of, union, dues, f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43992cdf-03c0-4edd-8e23-6295ba441b03')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-43992cdf-03c0-4edd-8e23-6295ba441b03 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-43992cdf-03c0-4edd-8e23-6295ba441b03');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split (news1['text_clean'], news1['fake'],random_state = 3)"
      ],
      "metadata": {
        "id": "Hnx4Cn8IWuRg"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the word2vec model\n",
        "w2v_model = gensim.models.Word2Vec(X_train,\n",
        "                                   size=100,\n",
        "                                   window=5,\n",
        "                                   min_count=2)"
      ],
      "metadata": {
        "id": "my7nNzpLWuPV"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate aggregated sentence vectors based on the word vectors for each word in the sentence\n",
        "#This code makes an array of all the sentences in which each sentence is an array of words in that sentence\n",
        "import numpy as np\n",
        "words = set(w2v_model.wv.index2word )\n",
        "X_train_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
        "                         for ls in X_train])\n",
        "X_test_vect = np.array([np.array([w2v_model.wv[i] for i in ls if i in words])\n",
        "                         for ls in X_test])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18uKpnxjWuNi",
        "outputId": "6201d92d-5cec-4096-93e4-a7aeb67dd672"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Why is the length of the sentence different than the length of the sentence vector?\n",
        "#Here as seen, we see that each sentence has different no. of vectors.\n",
        "# This is going to be difficult to train the model\n",
        "for i, v in enumerate(X_train_vect):\n",
        "    print(len(X_train.iloc[i]), len(v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGprpWPwWuLX",
        "outputId": "051a89d2-c831-4c5b-eb0c-4a7e4e5bd2ec"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "93 92\n",
            "198 195\n",
            "679 669\n",
            "412 398\n",
            "1224 1196\n",
            "72 69\n",
            "117 117\n",
            "185 182\n",
            "260 249\n",
            "309 303\n",
            "509 503\n",
            "63 60\n",
            "471 460\n",
            "67 65\n",
            "198 195\n",
            "708 692\n",
            "745 723\n",
            "122 120\n",
            "270 268\n",
            "347 343\n",
            "306 292\n",
            "379 366\n",
            "325 311\n",
            "347 333\n",
            "138 137\n",
            "2 2\n",
            "219 217\n",
            "328 326\n",
            "583 548\n",
            "714 687\n",
            "873 867\n",
            "702 683\n",
            "70 70\n",
            "115 114\n",
            "378 374\n",
            "51 49\n",
            "329 329\n",
            "506 492\n",
            "283 277\n",
            "114 114\n",
            "0 0\n",
            "185 183\n",
            "389 370\n",
            "175 174\n",
            "463 455\n",
            "475 469\n",
            "194 191\n",
            "199 198\n",
            "261 261\n",
            "75 72\n",
            "193 190\n",
            "294 288\n",
            "270 259\n",
            "437 412\n",
            "278 261\n",
            "825 801\n",
            "479 467\n",
            "328 313\n",
            "524 513\n",
            "176 174\n",
            "227 219\n",
            "95 89\n",
            "267 252\n",
            "59 58\n",
            "280 265\n",
            "386 365\n",
            "258 255\n",
            "332 323\n",
            "235 228\n",
            "196 189\n",
            "588 571\n",
            "294 280\n",
            "303 297\n",
            "801 783\n",
            "274 272\n",
            "337 316\n",
            "98 89\n",
            "716 706\n",
            "495 485\n",
            "472 467\n",
            "613 608\n",
            "73 73\n",
            "204 201\n",
            "633 619\n",
            "551 516\n",
            "24 19\n",
            "162 156\n",
            "60 60\n",
            "478 470\n",
            "365 360\n",
            "601 596\n",
            "178 174\n",
            "338 333\n",
            "803 772\n",
            "469 462\n",
            "613 604\n",
            "1370 1346\n",
            "402 393\n",
            "359 347\n",
            "486 475\n",
            "137 134\n",
            "63 63\n",
            "56 56\n",
            "307 298\n",
            "492 476\n",
            "493 477\n",
            "215 204\n",
            "78 77\n",
            "338 334\n",
            "632 619\n",
            "1166 1123\n",
            "268 261\n",
            "139 137\n",
            "219 216\n",
            "288 288\n",
            "498 489\n",
            "171 171\n",
            "262 256\n",
            "133 130\n",
            "768 737\n",
            "358 347\n",
            "311 304\n",
            "508 497\n",
            "315 313\n",
            "610 593\n",
            "490 480\n",
            "675 666\n",
            "274 263\n",
            "205 193\n",
            "359 347\n",
            "378 375\n",
            "379 369\n",
            "416 396\n",
            "67 67\n",
            "340 333\n",
            "248 248\n",
            "0 0\n",
            "17 17\n",
            "6 6\n",
            "264 263\n",
            "278 269\n",
            "408 397\n",
            "128 127\n",
            "89 87\n",
            "387 374\n",
            "338 329\n",
            "804 792\n",
            "243 237\n",
            "851 840\n",
            "891 883\n",
            "76 75\n",
            "235 227\n",
            "649 639\n",
            "389 382\n",
            "204 198\n",
            "76 75\n",
            "338 334\n",
            "702 681\n",
            "151 144\n",
            "138 136\n",
            "200 197\n",
            "410 409\n",
            "217 211\n",
            "356 349\n",
            "971 958\n",
            "3134 3134\n",
            "433 423\n",
            "739 737\n",
            "362 353\n",
            "318 313\n",
            "97 93\n",
            "38 37\n",
            "0 0\n",
            "90 90\n",
            "303 299\n",
            "279 278\n",
            "116 115\n",
            "444 392\n",
            "376 369\n",
            "414 394\n",
            "186 179\n",
            "259 255\n",
            "479 463\n",
            "472 455\n",
            "287 282\n",
            "166 164\n",
            "526 514\n",
            "2016 1954\n",
            "569 557\n",
            "387 379\n",
            "288 280\n",
            "634 614\n",
            "283 275\n",
            "47 44\n",
            "884 868\n",
            "148 143\n",
            "302 291\n",
            "718 700\n",
            "269 256\n",
            "89 84\n",
            "59 58\n",
            "296 290\n",
            "352 344\n",
            "322 315\n",
            "672 659\n",
            "819 783\n",
            "1348 1312\n",
            "450 434\n",
            "941 932\n",
            "1264 1248\n",
            "305 295\n",
            "255 248\n",
            "273 267\n",
            "363 361\n",
            "547 538\n",
            "1285 1199\n",
            "40 40\n",
            "82 82\n",
            "97 97\n",
            "277 269\n",
            "443 434\n",
            "389 379\n",
            "1017 987\n",
            "499 481\n",
            "782 742\n",
            "1686 1640\n",
            "699 676\n",
            "2784 2726\n",
            "235 225\n",
            "326 298\n",
            "173 170\n",
            "526 513\n",
            "160 158\n",
            "527 524\n",
            "301 299\n",
            "434 416\n",
            "1011 984\n",
            "74 74\n",
            "504 496\n",
            "909 894\n",
            "237 229\n",
            "81 80\n",
            "93 90\n",
            "553 535\n",
            "142 134\n",
            "1424 1385\n",
            "271 266\n",
            "74 73\n",
            "431 415\n",
            "16 16\n",
            "126 125\n",
            "619 596\n",
            "489 449\n",
            "399 390\n",
            "357 354\n",
            "62 62\n",
            "339 334\n",
            "635 617\n",
            "1158 1135\n",
            "108 107\n",
            "81 80\n",
            "685 678\n",
            "260 241\n",
            "0 0\n",
            "212 201\n",
            "267 262\n",
            "469 463\n",
            "587 567\n",
            "533 521\n",
            "65 63\n",
            "210 208\n",
            "244 234\n",
            "285 271\n",
            "0 0\n",
            "697 690\n",
            "330 319\n",
            "304 297\n",
            "521 516\n",
            "401 397\n",
            "558 547\n",
            "351 336\n",
            "163 162\n",
            "373 363\n",
            "512 503\n",
            "517 511\n",
            "372 358\n",
            "378 373\n",
            "90 90\n",
            "137 133\n",
            "631 604\n",
            "763 742\n",
            "99 99\n",
            "1310 1276\n",
            "344 341\n",
            "269 268\n",
            "286 281\n",
            "509 493\n",
            "547 535\n",
            "138 131\n",
            "142 140\n",
            "335 321\n",
            "383 378\n",
            "31 29\n",
            "501 483\n",
            "377 369\n",
            "86 86\n",
            "414 385\n",
            "330 322\n",
            "890 863\n",
            "0 0\n",
            "225 224\n",
            "381 370\n",
            "317 309\n",
            "563 535\n",
            "1443 1406\n",
            "148 144\n",
            "400 398\n",
            "382 370\n",
            "615 597\n",
            "462 449\n",
            "161 157\n",
            "739 726\n",
            "303 297\n",
            "12 12\n",
            "518 512\n",
            "338 327\n",
            "87 83\n",
            "326 307\n",
            "693 684\n",
            "193 185\n",
            "68 65\n",
            "168 163\n",
            "569 542\n",
            "413 403\n",
            "125 121\n",
            "729 691\n",
            "137 133\n",
            "325 306\n",
            "151 149\n",
            "581 572\n",
            "1919 1841\n",
            "54 52\n",
            "282 275\n",
            "861 855\n",
            "265 255\n",
            "307 298\n",
            "363 352\n",
            "387 381\n",
            "386 361\n",
            "437 422\n",
            "375 366\n",
            "342 332\n",
            "342 340\n",
            "505 497\n",
            "740 689\n",
            "276 269\n",
            "633 611\n",
            "32 31\n",
            "68 68\n",
            "247 244\n",
            "151 148\n",
            "853 845\n",
            "448 424\n",
            "707 695\n",
            "170 163\n",
            "38 38\n",
            "396 392\n",
            "693 659\n",
            "285 280\n",
            "131 128\n",
            "711 703\n",
            "313 304\n",
            "388 385\n",
            "146 145\n",
            "820 808\n",
            "301 292\n",
            "173 171\n",
            "246 243\n",
            "449 438\n",
            "179 170\n",
            "229 227\n",
            "533 529\n",
            "437 427\n",
            "1200 1176\n",
            "437 425\n",
            "155 148\n",
            "441 425\n",
            "351 345\n",
            "384 377\n",
            "396 386\n",
            "396 390\n",
            "173 169\n",
            "86 84\n",
            "161 146\n",
            "433 426\n",
            "660 652\n",
            "458 442\n",
            "51 51\n",
            "1491 1417\n",
            "329 322\n",
            "197 190\n",
            "349 341\n",
            "270 266\n",
            "268 258\n",
            "1122 1100\n",
            "0 0\n",
            "338 304\n",
            "363 360\n",
            "356 341\n",
            "634 613\n",
            "83 77\n",
            "22 21\n",
            "718 697\n",
            "592 585\n",
            "271 269\n",
            "503 484\n",
            "75 75\n",
            "3134 3134\n",
            "554 534\n",
            "392 375\n",
            "356 350\n",
            "36 34\n",
            "954 923\n",
            "267 265\n",
            "427 416\n",
            "701 686\n",
            "531 519\n",
            "93 90\n",
            "144 134\n",
            "362 351\n",
            "130 120\n",
            "97 95\n",
            "582 573\n",
            "522 513\n",
            "436 406\n",
            "32 31\n",
            "138 132\n",
            "572 566\n",
            "88 85\n",
            "75 73\n",
            "24 14\n",
            "583 561\n",
            "1522 1522\n",
            "368 361\n",
            "422 417\n",
            "66 66\n",
            "776 760\n",
            "76 76\n",
            "7 7\n",
            "160 154\n",
            "100 99\n",
            "210 204\n",
            "448 424\n",
            "543 523\n",
            "227 223\n",
            "55 53\n",
            "681 669\n",
            "346 335\n",
            "204 197\n",
            "765 744\n",
            "306 304\n",
            "477 462\n",
            "875 868\n",
            "1099 1079\n",
            "194 183\n",
            "298 289\n",
            "398 389\n",
            "421 408\n",
            "305 299\n",
            "316 296\n",
            "465 463\n",
            "372 363\n",
            "128 126\n",
            "594 579\n",
            "693 665\n",
            "654 645\n",
            "70 63\n",
            "272 268\n",
            "404 386\n",
            "131 128\n",
            "714 698\n",
            "363 360\n",
            "335 330\n",
            "996 959\n",
            "444 431\n",
            "445 430\n",
            "333 321\n",
            "100 99\n",
            "345 339\n",
            "534 523\n",
            "345 341\n",
            "107 107\n",
            "1092 1065\n",
            "445 432\n",
            "536 529\n",
            "597 577\n",
            "104 102\n",
            "56 56\n",
            "3737 3637\n",
            "125 125\n",
            "114 113\n",
            "388 377\n",
            "467 456\n",
            "52 52\n",
            "75 73\n",
            "0 0\n",
            "571 568\n",
            "44 42\n",
            "100 97\n",
            "300 288\n",
            "505 496\n",
            "433 420\n",
            "260 253\n",
            "343 330\n",
            "303 301\n",
            "832 813\n",
            "469 466\n",
            "416 402\n",
            "515 510\n",
            "111 108\n",
            "1760 1700\n",
            "475 462\n",
            "58 54\n",
            "206 205\n",
            "285 277\n",
            "580 565\n",
            "639 629\n",
            "48 48\n",
            "433 427\n",
            "524 517\n",
            "365 360\n",
            "368 366\n",
            "345 340\n",
            "450 441\n",
            "591 570\n",
            "242 238\n",
            "303 296\n",
            "2542 2400\n",
            "273 267\n",
            "430 426\n",
            "88 87\n",
            "270 260\n",
            "389 378\n",
            "454 432\n",
            "534 518\n",
            "518 502\n",
            "599 580\n",
            "654 641\n",
            "606 597\n",
            "768 747\n",
            "893 866\n",
            "219 215\n",
            "822 813\n",
            "471 455\n",
            "1522 1522\n",
            "209 207\n",
            "317 301\n",
            "376 371\n",
            "11 11\n",
            "685 672\n",
            "64 64\n",
            "187 180\n",
            "1058 1033\n",
            "700 697\n",
            "379 374\n",
            "435 429\n",
            "375 365\n",
            "627 610\n",
            "787 766\n",
            "1150 1138\n",
            "162 159\n",
            "375 369\n",
            "92 90\n",
            "457 453\n",
            "363 336\n",
            "589 571\n",
            "367 349\n",
            "839 806\n",
            "2501 2422\n",
            "272 267\n",
            "0 0\n",
            "419 408\n",
            "366 355\n",
            "387 381\n",
            "458 455\n",
            "402 376\n",
            "443 440\n",
            "642 624\n",
            "460 438\n",
            "385 379\n",
            "367 351\n",
            "479 468\n",
            "46 46\n",
            "313 302\n",
            "531 524\n",
            "271 264\n",
            "511 499\n",
            "672 653\n",
            "627 610\n",
            "142 139\n",
            "143 143\n",
            "350 341\n",
            "251 244\n",
            "130 128\n",
            "1088 1071\n",
            "600 578\n",
            "13 12\n",
            "329 329\n",
            "754 724\n",
            "423 403\n",
            "600 600\n",
            "674 665\n",
            "667 645\n",
            "538 528\n",
            "324 317\n",
            "185 182\n",
            "854 840\n",
            "520 498\n",
            "599 561\n",
            "2058 1984\n",
            "463 443\n",
            "596 589\n",
            "539 523\n",
            "272 265\n",
            "338 333\n",
            "709 691\n",
            "728 702\n",
            "283 277\n",
            "8 7\n",
            "174 172\n",
            "557 524\n",
            "50 50\n",
            "413 396\n",
            "451 441\n",
            "50 44\n",
            "375 368\n",
            "85 85\n",
            "595 566\n",
            "256 256\n",
            "61 60\n",
            "80 80\n",
            "396 379\n",
            "342 333\n",
            "114 107\n",
            "363 355\n",
            "403 397\n",
            "113 112\n",
            "394 386\n",
            "215 212\n",
            "595 581\n",
            "476 457\n",
            "245 243\n",
            "241 228\n",
            "85 82\n",
            "346 333\n",
            "366 362\n",
            "413 404\n",
            "135 133\n",
            "537 517\n",
            "419 410\n",
            "413 399\n",
            "263 256\n",
            "83 82\n",
            "359 350\n",
            "383 380\n",
            "388 379\n",
            "135 135\n",
            "834 808\n",
            "560 542\n",
            "474 460\n",
            "52 48\n",
            "395 389\n",
            "846 818\n",
            "466 464\n",
            "746 732\n",
            "100 95\n",
            "452 415\n",
            "464 444\n",
            "573 559\n",
            "385 375\n",
            "272 261\n",
            "490 479\n",
            "287 279\n",
            "518 505\n",
            "349 345\n",
            "388 382\n",
            "25 23\n",
            "506 494\n",
            "273 269\n",
            "262 248\n",
            "54 52\n",
            "761 742\n",
            "90 86\n",
            "70 70\n",
            "390 386\n",
            "66 64\n",
            "798 778\n",
            "240 232\n",
            "389 385\n",
            "203 199\n",
            "368 359\n",
            "264 261\n",
            "404 397\n",
            "108 100\n",
            "99 94\n",
            "246 241\n",
            "291 282\n",
            "455 448\n",
            "465 460\n",
            "0 0\n",
            "169 165\n",
            "24 23\n",
            "85 85\n",
            "427 421\n",
            "75 74\n",
            "419 416\n",
            "157 150\n",
            "764 737\n",
            "306 301\n",
            "659 649\n",
            "86 83\n",
            "409 401\n",
            "409 403\n",
            "151 147\n",
            "848 768\n",
            "116 112\n",
            "128 128\n",
            "88 88\n",
            "301 294\n",
            "1 1\n",
            "49 48\n",
            "495 484\n",
            "343 337\n",
            "198 191\n",
            "94 92\n",
            "57 55\n",
            "265 258\n",
            "195 190\n",
            "404 392\n",
            "341 329\n",
            "400 396\n",
            "75 74\n",
            "99 99\n",
            "431 419\n",
            "112 112\n",
            "161 152\n",
            "178 174\n",
            "393 384\n",
            "229 226\n",
            "314 303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute sentence vectors by averaging the word vectors for the words contained in the sentence\n",
        "#Here, we are averaging all features of vectors in a sentence to get a single vector for each sentence having 100 dimensions\n",
        "X_train_vect_avg = []\n",
        "for v in X_train_vect:\n",
        "    if v.size:\n",
        "        X_train_vect_avg.append(v.mean(axis=0))\n",
        "    else:\n",
        "        X_train_vect_avg.append(np.zeros(100, dtype=float))\n",
        "        \n",
        "X_test_vect_avg = []\n",
        "for v in X_test_vect:\n",
        "    if v.size:\n",
        "        X_test_vect_avg.append(v.mean(axis=0))\n",
        "    else:\n",
        "        X_test_vect_avg.append(np.zeros(100, dtype=float))"
      ],
      "metadata": {
        "id": "0uuVnd3PWuJT"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Are our sentence vector lengths consistent?\n",
        "for i, v in enumerate(X_train_vect_avg):\n",
        "    print(len(X_train.iloc[i]), len(v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRQHbOEXWuHY",
        "outputId": "94bd76f6-88d2-457e-ac9c-037e465fc65f"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "93 100\n",
            "198 100\n",
            "679 100\n",
            "412 100\n",
            "1224 100\n",
            "72 100\n",
            "117 100\n",
            "185 100\n",
            "260 100\n",
            "309 100\n",
            "509 100\n",
            "63 100\n",
            "471 100\n",
            "67 100\n",
            "198 100\n",
            "708 100\n",
            "745 100\n",
            "122 100\n",
            "270 100\n",
            "347 100\n",
            "306 100\n",
            "379 100\n",
            "325 100\n",
            "347 100\n",
            "138 100\n",
            "2 100\n",
            "219 100\n",
            "328 100\n",
            "583 100\n",
            "714 100\n",
            "873 100\n",
            "702 100\n",
            "70 100\n",
            "115 100\n",
            "378 100\n",
            "51 100\n",
            "329 100\n",
            "506 100\n",
            "283 100\n",
            "114 100\n",
            "0 100\n",
            "185 100\n",
            "389 100\n",
            "175 100\n",
            "463 100\n",
            "475 100\n",
            "194 100\n",
            "199 100\n",
            "261 100\n",
            "75 100\n",
            "193 100\n",
            "294 100\n",
            "270 100\n",
            "437 100\n",
            "278 100\n",
            "825 100\n",
            "479 100\n",
            "328 100\n",
            "524 100\n",
            "176 100\n",
            "227 100\n",
            "95 100\n",
            "267 100\n",
            "59 100\n",
            "280 100\n",
            "386 100\n",
            "258 100\n",
            "332 100\n",
            "235 100\n",
            "196 100\n",
            "588 100\n",
            "294 100\n",
            "303 100\n",
            "801 100\n",
            "274 100\n",
            "337 100\n",
            "98 100\n",
            "716 100\n",
            "495 100\n",
            "472 100\n",
            "613 100\n",
            "73 100\n",
            "204 100\n",
            "633 100\n",
            "551 100\n",
            "24 100\n",
            "162 100\n",
            "60 100\n",
            "478 100\n",
            "365 100\n",
            "601 100\n",
            "178 100\n",
            "338 100\n",
            "803 100\n",
            "469 100\n",
            "613 100\n",
            "1370 100\n",
            "402 100\n",
            "359 100\n",
            "486 100\n",
            "137 100\n",
            "63 100\n",
            "56 100\n",
            "307 100\n",
            "492 100\n",
            "493 100\n",
            "215 100\n",
            "78 100\n",
            "338 100\n",
            "632 100\n",
            "1166 100\n",
            "268 100\n",
            "139 100\n",
            "219 100\n",
            "288 100\n",
            "498 100\n",
            "171 100\n",
            "262 100\n",
            "133 100\n",
            "768 100\n",
            "358 100\n",
            "311 100\n",
            "508 100\n",
            "315 100\n",
            "610 100\n",
            "490 100\n",
            "675 100\n",
            "274 100\n",
            "205 100\n",
            "359 100\n",
            "378 100\n",
            "379 100\n",
            "416 100\n",
            "67 100\n",
            "340 100\n",
            "248 100\n",
            "0 100\n",
            "17 100\n",
            "6 100\n",
            "264 100\n",
            "278 100\n",
            "408 100\n",
            "128 100\n",
            "89 100\n",
            "387 100\n",
            "338 100\n",
            "804 100\n",
            "243 100\n",
            "851 100\n",
            "891 100\n",
            "76 100\n",
            "235 100\n",
            "649 100\n",
            "389 100\n",
            "204 100\n",
            "76 100\n",
            "338 100\n",
            "702 100\n",
            "151 100\n",
            "138 100\n",
            "200 100\n",
            "410 100\n",
            "217 100\n",
            "356 100\n",
            "971 100\n",
            "3134 100\n",
            "433 100\n",
            "739 100\n",
            "362 100\n",
            "318 100\n",
            "97 100\n",
            "38 100\n",
            "0 100\n",
            "90 100\n",
            "303 100\n",
            "279 100\n",
            "116 100\n",
            "444 100\n",
            "376 100\n",
            "414 100\n",
            "186 100\n",
            "259 100\n",
            "479 100\n",
            "472 100\n",
            "287 100\n",
            "166 100\n",
            "526 100\n",
            "2016 100\n",
            "569 100\n",
            "387 100\n",
            "288 100\n",
            "634 100\n",
            "283 100\n",
            "47 100\n",
            "884 100\n",
            "148 100\n",
            "302 100\n",
            "718 100\n",
            "269 100\n",
            "89 100\n",
            "59 100\n",
            "296 100\n",
            "352 100\n",
            "322 100\n",
            "672 100\n",
            "819 100\n",
            "1348 100\n",
            "450 100\n",
            "941 100\n",
            "1264 100\n",
            "305 100\n",
            "255 100\n",
            "273 100\n",
            "363 100\n",
            "547 100\n",
            "1285 100\n",
            "40 100\n",
            "82 100\n",
            "97 100\n",
            "277 100\n",
            "443 100\n",
            "389 100\n",
            "1017 100\n",
            "499 100\n",
            "782 100\n",
            "1686 100\n",
            "699 100\n",
            "2784 100\n",
            "235 100\n",
            "326 100\n",
            "173 100\n",
            "526 100\n",
            "160 100\n",
            "527 100\n",
            "301 100\n",
            "434 100\n",
            "1011 100\n",
            "74 100\n",
            "504 100\n",
            "909 100\n",
            "237 100\n",
            "81 100\n",
            "93 100\n",
            "553 100\n",
            "142 100\n",
            "1424 100\n",
            "271 100\n",
            "74 100\n",
            "431 100\n",
            "16 100\n",
            "126 100\n",
            "619 100\n",
            "489 100\n",
            "399 100\n",
            "357 100\n",
            "62 100\n",
            "339 100\n",
            "635 100\n",
            "1158 100\n",
            "108 100\n",
            "81 100\n",
            "685 100\n",
            "260 100\n",
            "0 100\n",
            "212 100\n",
            "267 100\n",
            "469 100\n",
            "587 100\n",
            "533 100\n",
            "65 100\n",
            "210 100\n",
            "244 100\n",
            "285 100\n",
            "0 100\n",
            "697 100\n",
            "330 100\n",
            "304 100\n",
            "521 100\n",
            "401 100\n",
            "558 100\n",
            "351 100\n",
            "163 100\n",
            "373 100\n",
            "512 100\n",
            "517 100\n",
            "372 100\n",
            "378 100\n",
            "90 100\n",
            "137 100\n",
            "631 100\n",
            "763 100\n",
            "99 100\n",
            "1310 100\n",
            "344 100\n",
            "269 100\n",
            "286 100\n",
            "509 100\n",
            "547 100\n",
            "138 100\n",
            "142 100\n",
            "335 100\n",
            "383 100\n",
            "31 100\n",
            "501 100\n",
            "377 100\n",
            "86 100\n",
            "414 100\n",
            "330 100\n",
            "890 100\n",
            "0 100\n",
            "225 100\n",
            "381 100\n",
            "317 100\n",
            "563 100\n",
            "1443 100\n",
            "148 100\n",
            "400 100\n",
            "382 100\n",
            "615 100\n",
            "462 100\n",
            "161 100\n",
            "739 100\n",
            "303 100\n",
            "12 100\n",
            "518 100\n",
            "338 100\n",
            "87 100\n",
            "326 100\n",
            "693 100\n",
            "193 100\n",
            "68 100\n",
            "168 100\n",
            "569 100\n",
            "413 100\n",
            "125 100\n",
            "729 100\n",
            "137 100\n",
            "325 100\n",
            "151 100\n",
            "581 100\n",
            "1919 100\n",
            "54 100\n",
            "282 100\n",
            "861 100\n",
            "265 100\n",
            "307 100\n",
            "363 100\n",
            "387 100\n",
            "386 100\n",
            "437 100\n",
            "375 100\n",
            "342 100\n",
            "342 100\n",
            "505 100\n",
            "740 100\n",
            "276 100\n",
            "633 100\n",
            "32 100\n",
            "68 100\n",
            "247 100\n",
            "151 100\n",
            "853 100\n",
            "448 100\n",
            "707 100\n",
            "170 100\n",
            "38 100\n",
            "396 100\n",
            "693 100\n",
            "285 100\n",
            "131 100\n",
            "711 100\n",
            "313 100\n",
            "388 100\n",
            "146 100\n",
            "820 100\n",
            "301 100\n",
            "173 100\n",
            "246 100\n",
            "449 100\n",
            "179 100\n",
            "229 100\n",
            "533 100\n",
            "437 100\n",
            "1200 100\n",
            "437 100\n",
            "155 100\n",
            "441 100\n",
            "351 100\n",
            "384 100\n",
            "396 100\n",
            "396 100\n",
            "173 100\n",
            "86 100\n",
            "161 100\n",
            "433 100\n",
            "660 100\n",
            "458 100\n",
            "51 100\n",
            "1491 100\n",
            "329 100\n",
            "197 100\n",
            "349 100\n",
            "270 100\n",
            "268 100\n",
            "1122 100\n",
            "0 100\n",
            "338 100\n",
            "363 100\n",
            "356 100\n",
            "634 100\n",
            "83 100\n",
            "22 100\n",
            "718 100\n",
            "592 100\n",
            "271 100\n",
            "503 100\n",
            "75 100\n",
            "3134 100\n",
            "554 100\n",
            "392 100\n",
            "356 100\n",
            "36 100\n",
            "954 100\n",
            "267 100\n",
            "427 100\n",
            "701 100\n",
            "531 100\n",
            "93 100\n",
            "144 100\n",
            "362 100\n",
            "130 100\n",
            "97 100\n",
            "582 100\n",
            "522 100\n",
            "436 100\n",
            "32 100\n",
            "138 100\n",
            "572 100\n",
            "88 100\n",
            "75 100\n",
            "24 100\n",
            "583 100\n",
            "1522 100\n",
            "368 100\n",
            "422 100\n",
            "66 100\n",
            "776 100\n",
            "76 100\n",
            "7 100\n",
            "160 100\n",
            "100 100\n",
            "210 100\n",
            "448 100\n",
            "543 100\n",
            "227 100\n",
            "55 100\n",
            "681 100\n",
            "346 100\n",
            "204 100\n",
            "765 100\n",
            "306 100\n",
            "477 100\n",
            "875 100\n",
            "1099 100\n",
            "194 100\n",
            "298 100\n",
            "398 100\n",
            "421 100\n",
            "305 100\n",
            "316 100\n",
            "465 100\n",
            "372 100\n",
            "128 100\n",
            "594 100\n",
            "693 100\n",
            "654 100\n",
            "70 100\n",
            "272 100\n",
            "404 100\n",
            "131 100\n",
            "714 100\n",
            "363 100\n",
            "335 100\n",
            "996 100\n",
            "444 100\n",
            "445 100\n",
            "333 100\n",
            "100 100\n",
            "345 100\n",
            "534 100\n",
            "345 100\n",
            "107 100\n",
            "1092 100\n",
            "445 100\n",
            "536 100\n",
            "597 100\n",
            "104 100\n",
            "56 100\n",
            "3737 100\n",
            "125 100\n",
            "114 100\n",
            "388 100\n",
            "467 100\n",
            "52 100\n",
            "75 100\n",
            "0 100\n",
            "571 100\n",
            "44 100\n",
            "100 100\n",
            "300 100\n",
            "505 100\n",
            "433 100\n",
            "260 100\n",
            "343 100\n",
            "303 100\n",
            "832 100\n",
            "469 100\n",
            "416 100\n",
            "515 100\n",
            "111 100\n",
            "1760 100\n",
            "475 100\n",
            "58 100\n",
            "206 100\n",
            "285 100\n",
            "580 100\n",
            "639 100\n",
            "48 100\n",
            "433 100\n",
            "524 100\n",
            "365 100\n",
            "368 100\n",
            "345 100\n",
            "450 100\n",
            "591 100\n",
            "242 100\n",
            "303 100\n",
            "2542 100\n",
            "273 100\n",
            "430 100\n",
            "88 100\n",
            "270 100\n",
            "389 100\n",
            "454 100\n",
            "534 100\n",
            "518 100\n",
            "599 100\n",
            "654 100\n",
            "606 100\n",
            "768 100\n",
            "893 100\n",
            "219 100\n",
            "822 100\n",
            "471 100\n",
            "1522 100\n",
            "209 100\n",
            "317 100\n",
            "376 100\n",
            "11 100\n",
            "685 100\n",
            "64 100\n",
            "187 100\n",
            "1058 100\n",
            "700 100\n",
            "379 100\n",
            "435 100\n",
            "375 100\n",
            "627 100\n",
            "787 100\n",
            "1150 100\n",
            "162 100\n",
            "375 100\n",
            "92 100\n",
            "457 100\n",
            "363 100\n",
            "589 100\n",
            "367 100\n",
            "839 100\n",
            "2501 100\n",
            "272 100\n",
            "0 100\n",
            "419 100\n",
            "366 100\n",
            "387 100\n",
            "458 100\n",
            "402 100\n",
            "443 100\n",
            "642 100\n",
            "460 100\n",
            "385 100\n",
            "367 100\n",
            "479 100\n",
            "46 100\n",
            "313 100\n",
            "531 100\n",
            "271 100\n",
            "511 100\n",
            "672 100\n",
            "627 100\n",
            "142 100\n",
            "143 100\n",
            "350 100\n",
            "251 100\n",
            "130 100\n",
            "1088 100\n",
            "600 100\n",
            "13 100\n",
            "329 100\n",
            "754 100\n",
            "423 100\n",
            "600 100\n",
            "674 100\n",
            "667 100\n",
            "538 100\n",
            "324 100\n",
            "185 100\n",
            "854 100\n",
            "520 100\n",
            "599 100\n",
            "2058 100\n",
            "463 100\n",
            "596 100\n",
            "539 100\n",
            "272 100\n",
            "338 100\n",
            "709 100\n",
            "728 100\n",
            "283 100\n",
            "8 100\n",
            "174 100\n",
            "557 100\n",
            "50 100\n",
            "413 100\n",
            "451 100\n",
            "50 100\n",
            "375 100\n",
            "85 100\n",
            "595 100\n",
            "256 100\n",
            "61 100\n",
            "80 100\n",
            "396 100\n",
            "342 100\n",
            "114 100\n",
            "363 100\n",
            "403 100\n",
            "113 100\n",
            "394 100\n",
            "215 100\n",
            "595 100\n",
            "476 100\n",
            "245 100\n",
            "241 100\n",
            "85 100\n",
            "346 100\n",
            "366 100\n",
            "413 100\n",
            "135 100\n",
            "537 100\n",
            "419 100\n",
            "413 100\n",
            "263 100\n",
            "83 100\n",
            "359 100\n",
            "383 100\n",
            "388 100\n",
            "135 100\n",
            "834 100\n",
            "560 100\n",
            "474 100\n",
            "52 100\n",
            "395 100\n",
            "846 100\n",
            "466 100\n",
            "746 100\n",
            "100 100\n",
            "452 100\n",
            "464 100\n",
            "573 100\n",
            "385 100\n",
            "272 100\n",
            "490 100\n",
            "287 100\n",
            "518 100\n",
            "349 100\n",
            "388 100\n",
            "25 100\n",
            "506 100\n",
            "273 100\n",
            "262 100\n",
            "54 100\n",
            "761 100\n",
            "90 100\n",
            "70 100\n",
            "390 100\n",
            "66 100\n",
            "798 100\n",
            "240 100\n",
            "389 100\n",
            "203 100\n",
            "368 100\n",
            "264 100\n",
            "404 100\n",
            "108 100\n",
            "99 100\n",
            "246 100\n",
            "291 100\n",
            "455 100\n",
            "465 100\n",
            "0 100\n",
            "169 100\n",
            "24 100\n",
            "85 100\n",
            "427 100\n",
            "75 100\n",
            "419 100\n",
            "157 100\n",
            "764 100\n",
            "306 100\n",
            "659 100\n",
            "86 100\n",
            "409 100\n",
            "409 100\n",
            "151 100\n",
            "848 100\n",
            "116 100\n",
            "128 100\n",
            "88 100\n",
            "301 100\n",
            "1 100\n",
            "49 100\n",
            "495 100\n",
            "343 100\n",
            "198 100\n",
            "94 100\n",
            "57 100\n",
            "265 100\n",
            "195 100\n",
            "404 100\n",
            "341 100\n",
            "400 100\n",
            "75 100\n",
            "99 100\n",
            "431 100\n",
            "112 100\n",
            "161 100\n",
            "178 100\n",
            "393 100\n",
            "229 100\n",
            "314 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting a basic Random Forest model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier()\n",
        "rf_model = rf.fit(X_train_vect_avg, y_train.values.ravel())"
      ],
      "metadata": {
        "id": "rsM8DFl9WuFd"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Making predictions on the test data \n",
        "y_pred = rf_model.predict(X_test_vect_avg)"
      ],
      "metadata": {
        "id": "TgmJ4hYSWuD0"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating precision, recall and accuracy\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "print('Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
        "    round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YX06dD_9WuBe",
        "outputId": "0b36aa0e-6f07-4ad5-92a6-ffd8180c47cd"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.912 / Recall: 0.798 / Accuracy: 0.856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzjF68jRWt_b",
        "outputId": "c8cccfa8-eabb-4ae2-ae0b-0bc9c73be113"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[111,  10],\n",
              "       [ 26, 103]])"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Heatmap\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sn\n",
        "sn.heatmap(cm, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "5exWt4ByWt9D",
        "outputId": "1e82830b-5208-41c5-977d-ce29191a4ac5"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(33.0, 0.5, 'Truth')"
            ]
          },
          "metadata": {},
          "execution_count": 171
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Classification report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb-l2U_EWtx1",
        "outputId": "05d8065e-76d4-47d2-9de0-4b5553b477fc"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.92      0.86       121\n",
            "           1       0.91      0.80      0.85       129\n",
            "\n",
            "    accuracy                           0.86       250\n",
            "   macro avg       0.86      0.86      0.86       250\n",
            "weighted avg       0.86      0.86      0.86       250\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Contextual embeddings using BERT-base model**"
      ],
      "metadata": {
        "id": "nls01gJesVsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Here, we are using the BERT-base model to obtain vectors from each news text\n",
        "#BERT-base model is used which contains 12 hidden layers, hidden size of 768 and 12 attention heads\n",
        "#We split our dataset into test and train\n",
        "#We define the bert model consisting of input, preprocessing, encoding, neural network layers and finally producing output\n",
        "#These outputs are the probability values of the news text being fake or not. If these values are greater than 0.5, we assign fake label or 1 in our case. Otherwise, we provide label as 0.\n",
        "#Then we fit these models in 5 epochs\n"
      ],
      "metadata": {
        "id": "fPUrZv1hzXHm"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A dependency of the preprocessing for BERT inputs\n",
        "!pip install -q -U \"tensorflow-text==2.8.*\""
      ],
      "metadata": {
        "id": "q0-iKaXeGyec"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tf-models-official==2.7.0"
      ],
      "metadata": {
        "id": "7PYNJX2sHDsp"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "metadata": {
        "id": "e46WLnVbHEXk"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting into test and train\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(news1['text'],news1[\"fake\"], stratify = news1['fake'],random_state = 2)"
      ],
      "metadata": {
        "id": "1HTQ5ChdIiU3"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train1.head(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUIIS6UmJiKW",
        "outputId": "f5127c20-bcb2-4428-d2e8-fe80125ab3d1"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18871    ALMATY (Reuters) - The first prominent disside...\n",
              "7128     To say that David Brooks is not impressed with...\n",
              "10175    Katie Couric took to Twitter to call out Charl...\n",
              "17264    And they re heading to Cape Cod next! Where do...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BERT preprocessor and BERT encoder\n",
        "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")\n"
      ],
      "metadata": {
        "id": "EEH7RTzzJkL2"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining the bert model consisting of input, preprocessing, encoding, neural network layers and finally producing output\n",
        "# Bert layers\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessed_text = bert_preprocess(text_input)\n",
        "outputs = bert_encoder(preprocessed_text)\n",
        "\n",
        "# Neural network layers\n",
        "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
        "l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
        "\n",
        "# Use inputs and outputs to construct a final model\n",
        "model = tf.keras.Model(inputs=[text_input], outputs = [l])"
      ],
      "metadata": {
        "id": "H7XIA8ssJzOP"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7S07GsfIKcfk",
        "outputId": "110ba4f7-3061-4eee-9c89-0398569ac259"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " keras_layer_4 (KerasLayer)     {'input_type_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128),                                                          \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " keras_layer_5 (KerasLayer)     {'default': (None,   109482241   ['keras_layer_4[0][0]',          \n",
            "                                768),                             'keras_layer_4[0][1]',          \n",
            "                                 'sequence_output':               'keras_layer_4[0][2]']          \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768),                                                       \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 128, 768),                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)]}                                               \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 768)          0           ['keras_layer_5[0][13]']         \n",
            "                                                                                                  \n",
            " output (Dense)                 (None, 1)            769         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,483,010\n",
            "Trainable params: 769\n",
            "Non-trainable params: 109,482,241\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining metrics for model evaluation\n",
        "METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall')\n",
        "]\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=METRICS)\n"
      ],
      "metadata": {
        "id": "5ArHxQ2AKyqJ"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the model\n",
        "model.fit(X_train1, y_train1, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vW84PIO7K1Bl",
        "outputId": "c932d571-30ab-471c-8000-792001672b47"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "24/24 [==============================] - 370s 15s/step - loss: 0.6927 - accuracy: 0.5680 - precision: 0.5739 - recall: 0.5280\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 355s 15s/step - loss: 0.6027 - accuracy: 0.7493 - precision: 0.7726 - recall: 0.7067\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 355s 15s/step - loss: 0.5516 - accuracy: 0.7747 - precision: 0.7754 - recall: 0.7733\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 354s 15s/step - loss: 0.4982 - accuracy: 0.8333 - precision: 0.8788 - recall: 0.7733\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 354s 15s/step - loss: 0.4630 - accuracy: 0.8453 - precision: 0.8472 - recall: 0.8427\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe513ef1150>"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test1, y_test1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAmoG9ZaKzJp",
        "outputId": "42f5fd67-a3da-4e4f-e53a-e97b3c69f274"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 121s 15s/step - loss: 0.4750 - accuracy: 0.8560 - precision: 0.8739 - recall: 0.8320\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4749678671360016,\n",
              " 0.8560000061988831,\n",
              " 0.8739495873451233,\n",
              " 0.8320000171661377]"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Making predictions\n",
        "y_predicted1 = model.predict(X_test1)\n",
        "y_predicted1 = y_predicted1.flatten()"
      ],
      "metadata": {
        "id": "AfmbIBnxKzIH"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing probability values to 0 and 1 based on whether the value is greater than 0.5 or not\n",
        "import numpy as np\n",
        "y_predicted1 = np.where(y_predicted1 > 0.5, 1, 0)\n",
        "y_predicted1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fGU3GSEKzGE",
        "outputId": "87052194-4946-46a7-9cbd-aad5bfbd6c8d"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "       1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cm1 = confusion_matrix(y_test1, y_predicted1)\n",
        "cm1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Hx8x8X0KzD5",
        "outputId": "486a981c-e045-40c6-95f1-3f0be338589b"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[110,  15],\n",
              "       [ 21, 104]])"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#heat map\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sn\n",
        "sn.heatmap(cm1, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "wZuWoLSHKzBW",
        "outputId": "894380ae-3291-4374-a833-60a90a14b45a"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(33.0, 0.5, 'Truth')"
            ]
          },
          "metadata": {},
          "execution_count": 137
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test1, y_predicted1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIL-Sc66Ky-h",
        "outputId": "17252635-0b32-4751-f1e1-07b1c22852ec"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       125\n",
            "           1       0.87      0.83      0.85       125\n",
            "\n",
            "    accuracy                           0.86       250\n",
            "   macro avg       0.86      0.86      0.86       250\n",
            "weighted avg       0.86      0.86      0.86       250\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Contextual embeddings using BERT-Large model**"
      ],
      "metadata": {
        "id": "q1KxPVF_4zgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This model contains 24 layers, 16 Attention layers and 1024 hidden dimensions\n",
        "#We split our dataset into test and train\n",
        "#We define the bert model consisting of input, preprocessing, encoding, neural network layers and finally producing output\n",
        "#These outputs are the probability values of the news text being fake or not. If these values are greater than 0.5, we assign fake label or 1 in our case. Otherwise, we provide label as 0.\n",
        "#Then we fit these models in 5 epochs\n"
      ],
      "metadata": {
        "id": "igsfLHN_UH7r"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BERT preprocessor and BERT encoder\n",
        "bert_preprocess1 = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_encoder1 = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/4\")"
      ],
      "metadata": {
        "id": "0y1HTzvoUH0R"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting into test and train\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(news1['text'],news1[\"fake\"], stratify = news1['fake'],random_state = 2)"
      ],
      "metadata": {
        "id": "LNMWI9lwUHqy"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining the bert model consisting of input, preprocessing, encoding, neural network layers and finally producing output\n",
        "# Bert layers\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessed_text = bert_preprocess1(text_input)\n",
        "outputs = bert_encoder1(preprocessed_text)\n",
        "\n",
        "# Neural network layers\n",
        "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
        "l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
        "\n",
        "# Use inputs and outputs to construct a final model\n",
        "model1 = tf.keras.Model(inputs=[text_input], outputs = [l])"
      ],
      "metadata": {
        "id": "zoVqllAP6EKO"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9CDpEYM6EIL",
        "outputId": "d56f4c6d-3e59-4673-d62b-aace6022cac2"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " keras_layer_2 (KerasLayer)     {'input_mask': (Non  0           ['text[0][0]']                   \n",
            "                                e, 128),                                                          \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " keras_layer_3 (KerasLayer)     {'pooled_output': (  335141889   ['keras_layer_2[0][0]',          \n",
            "                                None, 1024),                      'keras_layer_2[0][1]',          \n",
            "                                 'sequence_output':               'keras_layer_2[0][2]']          \n",
            "                                 (None, 128, 1024),                                               \n",
            "                                 'default': (None,                                                \n",
            "                                1024),                                                            \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 128, 1024)                                               \n",
            "                                , (None, 128, 1024)                                               \n",
            "                                , (None, 128, 1024)                                               \n",
            "                                , (None, 128, 1024)                                               \n",
            "                                , (None, 128, 1024)                                               \n",
            "                                , (None, 128, 1024)                                               \n",
            "                                , (None, 128, 1024)                                               \n",
            "                                , (None, 128, 1024)                                               \n",
            "                                , (None, 128, 1024)                                               \n",
            "                                , (None, 128, 1024)                                               \n",
            "                                , (None, 128, 1024)                                               \n",
            "                                , (None, 128, 1024)                                               \n",
            "                                , (None, 128, 1024)                                               \n",
            "                                , (None, 128, 1024)                                               \n",
            "                                , (None, 128, 1024)                                               \n",
            "                                , (None, 128, 1024)                                               \n",
            "                                , (None, 128, 1024)                                               \n",
            "                                , (None, 128, 1024)                                               \n",
            "                                , (None, 128, 1024)                                               \n",
            "                                , (None, 128, 1024)                                               \n",
            "                                , (None, 128, 1024)                                               \n",
            "                                , (None, 128, 1024)                                               \n",
            "                                , (None, 128, 1024)                                               \n",
            "                                , (None, 128, 1024)                                               \n",
            "                                ]}                                                                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 1024)         0           ['keras_layer_3[0][25]']         \n",
            "                                                                                                  \n",
            " output (Dense)                 (None, 1)            1025        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 335,142,914\n",
            "Trainable params: 1,025\n",
            "Non-trainable params: 335,141,889\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining metrics for model evaluation\n",
        "METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall')\n",
        "]\n",
        "\n",
        "model1.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=METRICS)\n"
      ],
      "metadata": {
        "id": "hW-jAI5W6EGY"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the model\n",
        "model1.fit(X_train2, y_train2, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl8knt_c6EEN",
        "outputId": "491b6676-f8b8-406c-b63b-1e9c66255558"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "24/24 [==============================] - 1210s 50s/step - loss: 0.7164 - accuracy: 0.5440 - precision: 0.5445 - recall: 0.5387\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 1187s 49s/step - loss: 0.6482 - accuracy: 0.6253 - precision: 0.6243 - recall: 0.6293\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 1190s 50s/step - loss: 0.6291 - accuracy: 0.6387 - precision: 0.6548 - recall: 0.5867\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 1185s 49s/step - loss: 0.6145 - accuracy: 0.6480 - precision: 0.6647 - recall: 0.5973\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 1179s 49s/step - loss: 0.5889 - accuracy: 0.6773 - precision: 0.6701 - recall: 0.6987\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe517b5e990>"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.evaluate(X_test2, y_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUl2PSc16ECJ",
        "outputId": "0391707c-69f9-4390-8c85-56166ed5584a"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 397s 49s/step - loss: 0.5681 - accuracy: 0.6720 - precision: 0.9778 - recall: 0.3520\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.568147599697113, 0.671999990940094, 0.9777777791023254, 0.35199999809265137]"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Making predictions\n",
        "y_predicted2 = model1.predict(X_test2)\n",
        "y_predicted2 = y_predicted2.flatten()"
      ],
      "metadata": {
        "id": "JrCfi0Lc6EAW"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing probability values to 0 and 1 based on whether the value is greater than 0.5 or not\n",
        "import numpy as np\n",
        "y_predicted2 = np.where(y_predicted2 > 0.5, 1, 0)\n",
        "y_predicted2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3Gz_UVH6D-T",
        "outputId": "c6112403-b623-49e1-8a9f-c7b5aea0cc98"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
              "       1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cm2 = confusion_matrix(y_test2, y_predicted2)\n",
        "cm2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJOc5gEJ6D7x",
        "outputId": "2a4bbabd-8752-4b42-80ea-d709df7456c1"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[124,   1],\n",
              "       [ 81,  44]])"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Heat map\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sn\n",
        "sn.heatmap(cm2, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "s2-ecMe766tH",
        "outputId": "c565d990-a829-418a-cfa5-d58c99d91a57"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(33.0, 0.5, 'Truth')"
            ]
          },
          "metadata": {},
          "execution_count": 146
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test2, y_predicted2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_o1JLio66q-",
        "outputId": "1882913c-2743-42e0-d5a4-4bed10ea7ccc"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.99      0.75       125\n",
            "           1       0.98      0.35      0.52       125\n",
            "\n",
            "    accuracy                           0.67       250\n",
            "   macro avg       0.79      0.67      0.63       250\n",
            "weighted avg       0.79      0.67      0.63       250\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Contextual embeddings using ALBERT-base model**"
      ],
      "metadata": {
        "id": "rimDgiyhfE6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We split our dataset into test and train\n",
        "#We define the Albert model consisting of input, preprocessing, encoding, neural network layers and finally producing output\n",
        "#These outputs are the probability values of the news text being fake or not. If these values are greater than 0.5, we assign fake label or 1 in our case. Otherwise, we provide label as 0.\n",
        "#Then we fit these models in 5 epochs"
      ],
      "metadata": {
        "id": "ExSUY3TV66oy"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ALBERT preprocessor and ALBERT encoder\n",
        "albert_preprocess = hub.KerasLayer(\"http://tfhub.dev/tensorflow/albert_en_preprocess/3\")\n",
        "albert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/albert_en_base/3\")"
      ],
      "metadata": {
        "id": "cYm8HHA-66k2"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting into test and train\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(news1['text'],news1[\"fake\"], stratify = news1['fake'],random_state = 2)"
      ],
      "metadata": {
        "id": "BGkmqyxBfjt3"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining the bert model consisting of input, preprocessing, encoding, neural network layers and finally producing output\n",
        "# AlBert layers\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessed_text = albert_preprocess(text_input)\n",
        "outputs = albert_encoder(preprocessed_text)\n",
        "\n",
        "# Neural network layers\n",
        "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
        "l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
        "\n",
        "# Use inputs and outputs to construct a final model\n",
        "almodel = tf.keras.Model(inputs=[text_input], outputs = [l])"
      ],
      "metadata": {
        "id": "er2WAu0Pfjgw"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "almodel.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qRa1CKYfjeD",
        "outputId": "b7bde94f-9c24-4ffc-9d36-337b28433553"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " keras_layer_6 (KerasLayer)     {'input_word_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128),                                                          \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " keras_layer_7 (KerasLayer)     {'pooled_output': (  11683584    ['keras_layer_6[0][0]',          \n",
            "                                None, 768),                       'keras_layer_6[0][1]',          \n",
            "                                 'encoder_outputs':               'keras_layer_6[0][2]']          \n",
            "                                 [(None, 128, 768),                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'default': (None,                                                \n",
            "                                768),                                                             \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 128, 768)}                                                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 768)          0           ['keras_layer_7[0][13]']         \n",
            "                                                                                                  \n",
            " output (Dense)                 (None, 1)            769         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,684,353\n",
            "Trainable params: 769\n",
            "Non-trainable params: 11,683,584\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining metrics for model evaluation\n",
        "METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall')\n",
        "]\n",
        "\n",
        "almodel.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=METRICS)\n"
      ],
      "metadata": {
        "id": "498yhG48fjap"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the model\n",
        "almodel.fit(X_train3, y_train3, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxsOmou8fjVH",
        "outputId": "5714f1ec-7275-4e26-e324-4a30c7af1cf4"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "24/24 [==============================] - 433s 17s/step - loss: 0.5408 - accuracy: 0.7373 - precision: 0.7330 - recall: 0.7467\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 359s 15s/step - loss: 0.3220 - accuracy: 0.9093 - precision: 0.8828 - recall: 0.9440\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 357s 15s/step - loss: 0.2509 - accuracy: 0.9280 - precision: 0.9105 - recall: 0.9493\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 363s 15s/step - loss: 0.2056 - accuracy: 0.9520 - precision: 0.9449 - recall: 0.9600\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 362s 15s/step - loss: 0.1753 - accuracy: 0.9587 - precision: 0.9456 - recall: 0.9733\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe4f76ac450>"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "almodel.evaluate(X_test3, y_test3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_aAnxtwghpQ",
        "outputId": "0b22d27a-1262-47fd-9d24-739a82e051e4"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 121s 15s/step - loss: 0.1760 - accuracy: 0.9680 - precision: 0.9835 - recall: 0.9520\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.17596982419490814,\n",
              " 0.9679999947547913,\n",
              " 0.9834710955619812,\n",
              " 0.9520000219345093]"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Making predictions\n",
        "y_predicted3 = almodel.predict(X_test3)\n",
        "y_predicted3 = y_predicted3.flatten()"
      ],
      "metadata": {
        "id": "6MU58uw7ghm-"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing probability values to 0 and 1 based on whether the value is greater than 0.5 or not\n",
        "import numpy as np\n",
        "y_predicted3 = np.where(y_predicted3 > 0.5, 1, 0)\n",
        "y_predicted3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxBV4loXghid",
        "outputId": "f2641e69-0809-497c-f58e-e7a5794983c1"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
              "       1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n",
              "       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
              "       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
              "       0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
              "       1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
              "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cm3 = confusion_matrix(y_test3, y_predicted3)\n",
        "cm3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxrIfq4wghdV",
        "outputId": "66bbd444-6a73-4a1a-b0ce-b403c19391d4"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[123,   2],\n",
              "       [  6, 119]])"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Heat map\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sn\n",
        "sn.heatmap(cm3, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "yCJjduFIhEH4",
        "outputId": "60c55a51-11b8-4c1c-8825-7ce36ebb4711"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(33.0, 0.5, 'Truth')"
            ]
          },
          "metadata": {},
          "execution_count": 159
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test3, y_predicted3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVzjPkIxhEGe",
        "outputId": "8757d495-caaf-4727-8504-fa0b24dee576"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.97       125\n",
            "           1       0.98      0.95      0.97       125\n",
            "\n",
            "    accuracy                           0.97       250\n",
            "   macro avg       0.97      0.97      0.97       250\n",
            "weighted avg       0.97      0.97      0.97       250\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Result summary**"
      ],
      "metadata": {
        "id": "bxuKB0mFszLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing classification reports for classification models using following word embeddings:"
      ],
      "metadata": {
        "id": "0G_nPOwUhEEj"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Word2vec\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xq12hJ_hD-a",
        "outputId": "e8105654-87b0-483c-8d9d-4ba06f662e45"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.92      0.86       121\n",
            "           1       0.91      0.80      0.85       129\n",
            "\n",
            "    accuracy                           0.86       250\n",
            "   macro avg       0.86      0.86      0.86       250\n",
            "weighted avg       0.86      0.86      0.86       250\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BERT-base\n",
        "print(classification_report(y_test1, y_predicted1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJzwa8cVtXno",
        "outputId": "03973744-a06a-4894-ef80-dafa4eeb6a96"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       125\n",
            "           1       0.87      0.83      0.85       125\n",
            "\n",
            "    accuracy                           0.86       250\n",
            "   macro avg       0.86      0.86      0.86       250\n",
            "weighted avg       0.86      0.86      0.86       250\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BERT-large\n",
        "print(classification_report(y_test2, y_predicted2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElvI5XvwtXhg",
        "outputId": "cfbfe897-1362-4327-9108-770f6a26fafb"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.99      0.75       125\n",
            "           1       0.98      0.35      0.52       125\n",
            "\n",
            "    accuracy                           0.67       250\n",
            "   macro avg       0.79      0.67      0.63       250\n",
            "weighted avg       0.79      0.67      0.63       250\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#AlBERT\n",
        "print(classification_report(y_test3, y_predicted3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCYtNV85tXWe",
        "outputId": "2224e21c-c78c-4a04-d869-edfb0129ec4c"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.97       125\n",
            "           1       0.98      0.95      0.97       125\n",
            "\n",
            "    accuracy                           0.97       250\n",
            "   macro avg       0.97      0.97      0.97       250\n",
            "weighted avg       0.97      0.97      0.97       250\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We observe that classification model using word2vec embedding gives almost same results as compared to models using BERT-base embedding.\n",
        "#Classification model with BERT-large embedding performs the worst giving low values for precision, recall and accuracy as compared to other cases\n",
        "#Classification model with AlBERT embedding outperforms all the other models giving very high values for recall, precision and accuracy(all values closer to 0.97)\n",
        "#For the task of binary text classification, we found that AlBERT model is the best as compared to BERT and word2vec."
      ],
      "metadata": {
        "id": "pEnPOCH3t0qz"
      },
      "execution_count": 182,
      "outputs": []
    }
  ]
}